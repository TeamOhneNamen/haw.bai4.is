{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "https://www.analyticsvidhya.com/blog/2018/10/predicting-stock-price-machine-learningnd-deep-learning-techniques-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst wird der Datensatz geladen. Anschließend wird der Datensatz in Trainings- und Testdaten aufgeteilt. Es werden 1/7 der Daten zur Validation des Modells genutzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>41.150</td>\n",
       "      <td>42.1300</td>\n",
       "      <td>41.0600</td>\n",
       "      <td>41.310</td>\n",
       "      <td>7012673</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>2015-05-08</td>\n",
       "      <td>49.230</td>\n",
       "      <td>49.8300</td>\n",
       "      <td>48.9300</td>\n",
       "      <td>49.040</td>\n",
       "      <td>6478195</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>2014-09-29</td>\n",
       "      <td>35.350</td>\n",
       "      <td>35.7500</td>\n",
       "      <td>34.9400</td>\n",
       "      <td>35.030</td>\n",
       "      <td>7492228</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2014-02-03</td>\n",
       "      <td>33.950</td>\n",
       "      <td>34.4800</td>\n",
       "      <td>33.0500</td>\n",
       "      <td>33.960</td>\n",
       "      <td>21743871</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>2014-09-08</td>\n",
       "      <td>37.960</td>\n",
       "      <td>38.4000</td>\n",
       "      <td>37.9600</td>\n",
       "      <td>38.230</td>\n",
       "      <td>7348230</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>46.200</td>\n",
       "      <td>46.8200</td>\n",
       "      <td>46.2000</td>\n",
       "      <td>46.470</td>\n",
       "      <td>6189311</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2014-01-13</td>\n",
       "      <td>29.180</td>\n",
       "      <td>29.5300</td>\n",
       "      <td>28.5800</td>\n",
       "      <td>28.650</td>\n",
       "      <td>10591701</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>2015-12-21</td>\n",
       "      <td>41.350</td>\n",
       "      <td>42.4300</td>\n",
       "      <td>41.3500</td>\n",
       "      <td>42.400</td>\n",
       "      <td>6597508</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>2016-11-18</td>\n",
       "      <td>46.150</td>\n",
       "      <td>46.4900</td>\n",
       "      <td>45.6200</td>\n",
       "      <td>46.260</td>\n",
       "      <td>7795053</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>38.660</td>\n",
       "      <td>39.0500</td>\n",
       "      <td>37.9100</td>\n",
       "      <td>38.360</td>\n",
       "      <td>8206668</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>38.630</td>\n",
       "      <td>39.7600</td>\n",
       "      <td>38.6200</td>\n",
       "      <td>38.980</td>\n",
       "      <td>12409620</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>50.500</td>\n",
       "      <td>50.5600</td>\n",
       "      <td>48.7900</td>\n",
       "      <td>48.970</td>\n",
       "      <td>9792147</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>36.080</td>\n",
       "      <td>36.7800</td>\n",
       "      <td>35.7900</td>\n",
       "      <td>36.600</td>\n",
       "      <td>5819281</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>2017-10-27</td>\n",
       "      <td>48.410</td>\n",
       "      <td>48.8900</td>\n",
       "      <td>47.3300</td>\n",
       "      <td>47.560</td>\n",
       "      <td>8591454</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>2015-08-21</td>\n",
       "      <td>41.400</td>\n",
       "      <td>41.6000</td>\n",
       "      <td>39.7500</td>\n",
       "      <td>39.750</td>\n",
       "      <td>16241613</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2013-04-22</td>\n",
       "      <td>15.990</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>15.5000</td>\n",
       "      <td>15.520</td>\n",
       "      <td>9227100</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>40.020</td>\n",
       "      <td>40.1600</td>\n",
       "      <td>38.8200</td>\n",
       "      <td>38.880</td>\n",
       "      <td>10113170</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>2017-10-19</td>\n",
       "      <td>51.570</td>\n",
       "      <td>51.8300</td>\n",
       "      <td>49.6332</td>\n",
       "      <td>51.510</td>\n",
       "      <td>7568214</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>2017-05-12</td>\n",
       "      <td>46.260</td>\n",
       "      <td>46.4400</td>\n",
       "      <td>45.7300</td>\n",
       "      <td>45.830</td>\n",
       "      <td>3888691</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>2017-06-23</td>\n",
       "      <td>49.000</td>\n",
       "      <td>49.1000</td>\n",
       "      <td>48.4700</td>\n",
       "      <td>48.630</td>\n",
       "      <td>12682001</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>2015-06-10</td>\n",
       "      <td>40.210</td>\n",
       "      <td>41.2130</td>\n",
       "      <td>39.7000</td>\n",
       "      <td>40.430</td>\n",
       "      <td>15731942</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>2014-12-12</td>\n",
       "      <td>51.675</td>\n",
       "      <td>51.7000</td>\n",
       "      <td>49.9000</td>\n",
       "      <td>49.970</td>\n",
       "      <td>15364034</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>2014-07-15</td>\n",
       "      <td>43.330</td>\n",
       "      <td>43.7300</td>\n",
       "      <td>42.7800</td>\n",
       "      <td>43.700</td>\n",
       "      <td>8360710</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>43.260</td>\n",
       "      <td>43.5900</td>\n",
       "      <td>42.7300</td>\n",
       "      <td>42.980</td>\n",
       "      <td>7215369</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2013-12-30</td>\n",
       "      <td>24.870</td>\n",
       "      <td>25.2500</td>\n",
       "      <td>24.6500</td>\n",
       "      <td>24.780</td>\n",
       "      <td>8841369</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>29.090</td>\n",
       "      <td>29.1600</td>\n",
       "      <td>28.1900</td>\n",
       "      <td>28.930</td>\n",
       "      <td>9467046</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>2017-03-14</td>\n",
       "      <td>42.060</td>\n",
       "      <td>42.1000</td>\n",
       "      <td>40.8400</td>\n",
       "      <td>41.210</td>\n",
       "      <td>10208460</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2013-04-15</td>\n",
       "      <td>16.200</td>\n",
       "      <td>16.3900</td>\n",
       "      <td>15.4700</td>\n",
       "      <td>15.590</td>\n",
       "      <td>6243400</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>2016-09-23</td>\n",
       "      <td>35.300</td>\n",
       "      <td>35.6700</td>\n",
       "      <td>34.9600</td>\n",
       "      <td>35.550</td>\n",
       "      <td>4603182</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>2017-03-10</td>\n",
       "      <td>43.460</td>\n",
       "      <td>43.9500</td>\n",
       "      <td>42.9700</td>\n",
       "      <td>43.900</td>\n",
       "      <td>6842316</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>2015-09-22</td>\n",
       "      <td>42.770</td>\n",
       "      <td>43.0800</td>\n",
       "      <td>40.9200</td>\n",
       "      <td>41.190</td>\n",
       "      <td>12483661</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>38.790</td>\n",
       "      <td>39.5500</td>\n",
       "      <td>38.6700</td>\n",
       "      <td>38.730</td>\n",
       "      <td>7932341</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>52.780</td>\n",
       "      <td>52.8388</td>\n",
       "      <td>52.4300</td>\n",
       "      <td>52.650</td>\n",
       "      <td>2967756</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>45.300</td>\n",
       "      <td>45.9700</td>\n",
       "      <td>45.2700</td>\n",
       "      <td>45.810</td>\n",
       "      <td>1827200</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2013-07-02</td>\n",
       "      <td>16.780</td>\n",
       "      <td>16.7900</td>\n",
       "      <td>16.3600</td>\n",
       "      <td>16.430</td>\n",
       "      <td>4009300</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>2016-06-24</td>\n",
       "      <td>28.200</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>27.0400</td>\n",
       "      <td>27.050</td>\n",
       "      <td>36049898</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>2014-11-18</td>\n",
       "      <td>43.755</td>\n",
       "      <td>45.4600</td>\n",
       "      <td>43.7550</td>\n",
       "      <td>45.050</td>\n",
       "      <td>14219440</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>2016-02-09</td>\n",
       "      <td>34.930</td>\n",
       "      <td>36.7500</td>\n",
       "      <td>34.9100</td>\n",
       "      <td>36.190</td>\n",
       "      <td>11143254</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>49.350</td>\n",
       "      <td>49.4500</td>\n",
       "      <td>48.4600</td>\n",
       "      <td>48.690</td>\n",
       "      <td>3618731</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2013-07-25</td>\n",
       "      <td>18.490</td>\n",
       "      <td>18.8500</td>\n",
       "      <td>18.3000</td>\n",
       "      <td>18.830</td>\n",
       "      <td>9851900</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>2016-03-11</td>\n",
       "      <td>41.890</td>\n",
       "      <td>42.5000</td>\n",
       "      <td>41.7000</td>\n",
       "      <td>42.470</td>\n",
       "      <td>5701486</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2013-05-23</td>\n",
       "      <td>17.480</td>\n",
       "      <td>18.4500</td>\n",
       "      <td>17.4400</td>\n",
       "      <td>18.190</td>\n",
       "      <td>7482400</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>2016-06-17</td>\n",
       "      <td>29.100</td>\n",
       "      <td>29.5500</td>\n",
       "      <td>28.8500</td>\n",
       "      <td>29.340</td>\n",
       "      <td>15301910</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>2015-03-30</td>\n",
       "      <td>53.240</td>\n",
       "      <td>53.8400</td>\n",
       "      <td>53.0500</td>\n",
       "      <td>53.640</td>\n",
       "      <td>8167282</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>2016-06-23</td>\n",
       "      <td>30.250</td>\n",
       "      <td>30.4900</td>\n",
       "      <td>29.7700</td>\n",
       "      <td>30.330</td>\n",
       "      <td>9139949</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2013-10-17</td>\n",
       "      <td>20.720</td>\n",
       "      <td>21.0600</td>\n",
       "      <td>20.6400</td>\n",
       "      <td>21.000</td>\n",
       "      <td>4487000</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2013-06-14</td>\n",
       "      <td>16.960</td>\n",
       "      <td>17.2500</td>\n",
       "      <td>16.8100</td>\n",
       "      <td>16.930</td>\n",
       "      <td>2572500</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>2015-04-20</td>\n",
       "      <td>48.610</td>\n",
       "      <td>49.7800</td>\n",
       "      <td>47.9100</td>\n",
       "      <td>49.760</td>\n",
       "      <td>9523520</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>2015-11-25</td>\n",
       "      <td>41.350</td>\n",
       "      <td>41.5000</td>\n",
       "      <td>40.9600</td>\n",
       "      <td>41.310</td>\n",
       "      <td>4276646</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>2014-05-09</td>\n",
       "      <td>37.960</td>\n",
       "      <td>38.7000</td>\n",
       "      <td>37.9100</td>\n",
       "      <td>38.260</td>\n",
       "      <td>9704405</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>2015-06-29</td>\n",
       "      <td>40.770</td>\n",
       "      <td>41.3200</td>\n",
       "      <td>39.5900</td>\n",
       "      <td>39.750</td>\n",
       "      <td>17651705</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>2017-06-14</td>\n",
       "      <td>49.640</td>\n",
       "      <td>49.7801</td>\n",
       "      <td>48.8900</td>\n",
       "      <td>49.390</td>\n",
       "      <td>4027798</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>2015-06-26</td>\n",
       "      <td>42.440</td>\n",
       "      <td>42.5800</td>\n",
       "      <td>41.3300</td>\n",
       "      <td>41.440</td>\n",
       "      <td>9819882</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2014-03-18</td>\n",
       "      <td>37.750</td>\n",
       "      <td>38.0400</td>\n",
       "      <td>37.0900</td>\n",
       "      <td>37.350</td>\n",
       "      <td>5716947</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>2017-03-17</td>\n",
       "      <td>42.000</td>\n",
       "      <td>42.2140</td>\n",
       "      <td>41.6000</td>\n",
       "      <td>41.720</td>\n",
       "      <td>10185798</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>2016-02-22</td>\n",
       "      <td>40.140</td>\n",
       "      <td>40.9300</td>\n",
       "      <td>40.0700</td>\n",
       "      <td>40.840</td>\n",
       "      <td>9997306</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>2016-06-03</td>\n",
       "      <td>31.590</td>\n",
       "      <td>31.6000</td>\n",
       "      <td>30.3700</td>\n",
       "      <td>30.810</td>\n",
       "      <td>12424133</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>2017-12-06</td>\n",
       "      <td>49.390</td>\n",
       "      <td>49.8100</td>\n",
       "      <td>49.1900</td>\n",
       "      <td>49.610</td>\n",
       "      <td>2835542</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>2015-04-30</td>\n",
       "      <td>48.500</td>\n",
       "      <td>49.4600</td>\n",
       "      <td>48.0100</td>\n",
       "      <td>48.285</td>\n",
       "      <td>9400367</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>2015-10-27</td>\n",
       "      <td>46.410</td>\n",
       "      <td>46.6900</td>\n",
       "      <td>45.6500</td>\n",
       "      <td>46.460</td>\n",
       "      <td>6824082</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1079 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date    open     high      low   close    volume Name\n",
       "1046  2017-04-05  41.150  42.1300  41.0600  41.310   7012673  AAL\n",
       "565   2015-05-08  49.230  49.8300  48.9300  49.040   6478195  AAL\n",
       "412   2014-09-29  35.350  35.7500  34.9400  35.030   7492228  AAL\n",
       "247   2014-02-03  33.950  34.4800  33.0500  33.960  21743871  AAL\n",
       "397   2014-09-08  37.960  38.4000  37.9600  38.230   7348230  AAL\n",
       "688   2015-11-02  46.200  46.8200  46.2000  46.470   6189311  AAL\n",
       "233   2014-01-13  29.180  29.5300  28.5800  28.650  10591701  AAL\n",
       "722   2015-12-21  41.350  42.4300  41.3500  42.400   6597508  AAL\n",
       "953   2016-11-18  46.150  46.4900  45.6200  46.260   7795053  AAL\n",
       "795   2016-04-07  38.660  39.0500  37.9100  38.360   8206668  AAL\n",
       "644   2015-08-31  38.630  39.7600  38.6200  38.980  12409620  AAL\n",
       "1100  2017-06-22  50.500  50.5600  48.7900  48.970   9792147  AAL\n",
       "310   2014-05-05  36.080  36.7800  35.7900  36.600   5819281  AAL\n",
       "1189  2017-10-27  48.410  48.8900  47.3300  47.560   8591454  AAL\n",
       "638   2015-08-21  41.400  41.6000  39.7500  39.750  16241613  AAL\n",
       "49    2013-04-22  15.990  16.0000  15.5000  15.520   9227100  AAL\n",
       "744   2016-01-25  40.020  40.1600  38.8200  38.880  10113170  AAL\n",
       "1183  2017-10-19  51.570  51.8300  49.6332  51.510   7568214  AAL\n",
       "1072  2017-05-12  46.260  46.4400  45.7300  45.830   3888691  AAL\n",
       "1101  2017-06-23  49.000  49.1000  48.4700  48.630  12682001  AAL\n",
       "587   2015-06-10  40.210  41.2130  39.7000  40.430  15731942  AAL\n",
       "465   2014-12-12  51.675  51.7000  49.9000  49.970  15364034  AAL\n",
       "359   2014-07-15  43.330  43.7300  42.7800  43.700   8360710  AAL\n",
       "358   2014-07-14  43.260  43.5900  42.7300  42.980   7215369  AAL\n",
       "224   2013-12-30  24.870  25.2500  24.6500  24.780   8841369  AAL\n",
       "856   2016-07-05  29.090  29.1600  28.1900  28.930   9467046  AAL\n",
       "1030  2017-03-14  42.060  42.1000  40.8400  41.210  10208460  AAL\n",
       "44    2013-04-15  16.200  16.3900  15.4700  15.590   6243400  AAL\n",
       "913   2016-09-23  35.300  35.6700  34.9600  35.550   4603182  AAL\n",
       "1028  2017-03-10  43.460  43.9500  42.9700  43.900   6842316  AAL\n",
       "...          ...     ...      ...      ...     ...       ...  ...\n",
       "659   2015-09-22  42.770  43.0800  40.9200  41.190  12483661  AAL\n",
       "797   2016-04-11  38.790  39.5500  38.6700  38.730   7932341  AAL\n",
       "1236  2018-01-05  52.780  52.8388  52.4300  52.650   2967756  AAL\n",
       "1201  2017-11-14  45.300  45.9700  45.2700  45.810   1827200  AAL\n",
       "99    2013-07-02  16.780  16.7900  16.3600  16.430   4009300  AAL\n",
       "850   2016-06-24  28.200  28.5000  27.0400  27.050  36049898  AAL\n",
       "448   2014-11-18  43.755  45.4600  43.7550  45.050  14219440  AAL\n",
       "755   2016-02-09  34.930  36.7500  34.9100  36.190  11143254  AAL\n",
       "976   2016-12-22  49.350  49.4500  48.4600  48.690   3618731  AAL\n",
       "115   2013-07-25  18.490  18.8500  18.3000  18.830   9851900  AAL\n",
       "777   2016-03-11  41.890  42.5000  41.7000  42.470   5701486  AAL\n",
       "72    2013-05-23  17.480  18.4500  17.4400  18.190   7482400  AAL\n",
       "845   2016-06-17  29.100  29.5500  28.8500  29.340  15301910  AAL\n",
       "537   2015-03-30  53.240  53.8400  53.0500  53.640   8167282  AAL\n",
       "849   2016-06-23  30.250  30.4900  29.7700  30.330   9139949  AAL\n",
       "174   2013-10-17  20.720  21.0600  20.6400  21.000   4487000  AAL\n",
       "87    2013-06-14  16.960  17.2500  16.8100  16.930   2572500  AAL\n",
       "551   2015-04-20  48.610  49.7800  47.9100  49.760   9523520  AAL\n",
       "705   2015-11-25  41.350  41.5000  40.9600  41.310   4276646  AAL\n",
       "314   2014-05-09  37.960  38.7000  37.9100  38.260   9704405  AAL\n",
       "600   2015-06-29  40.770  41.3200  39.5900  39.750  17651705  AAL\n",
       "1094  2017-06-14  49.640  49.7801  48.8900  49.390   4027798  AAL\n",
       "599   2015-06-26  42.440  42.5800  41.3300  41.440   9819882  AAL\n",
       "277   2014-03-18  37.750  38.0400  37.0900  37.350   5716947  AAL\n",
       "1033  2017-03-17  42.000  42.2140  41.6000  41.720  10185798  AAL\n",
       "763   2016-02-22  40.140  40.9300  40.0700  40.840   9997306  AAL\n",
       "835   2016-06-03  31.590  31.6000  30.3700  30.810  12424133  AAL\n",
       "1216  2017-12-06  49.390  49.8100  49.1900  49.610   2835542  AAL\n",
       "559   2015-04-30  48.500  49.4600  48.0100  48.285   9400367  AAL\n",
       "684   2015-10-27  46.410  46.6900  45.6500  46.460   6824082  AAL\n",
       "\n",
       "[1079 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data_file = 'all_stocks_5yr.csv'\n",
    "df = pd.read_csv(stock_data_file)\n",
    "company = 'AAL'\n",
    "train, test = train_test_split(df[df['Name'] == company], test_size=1/7.0, random_state=0)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wird das Neuronale-Netz aufgebaut. Es handelt sich hierbei um ein fully-connected Netz mit zwei Hidden-Layern. Die Hidden-Layer nutzen als Aktivierungsfunktion jeweils die ReLu-Funktion, während der Output-Layer zur Klassifizierung die Sigmoid-Funktion nutzt. Die Anzahl der Input-Neuronen entspricht der Anzahl der Pixel im Bild."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 7)                 56        \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(len(df.columns), input_dim=len(df.columns), activation='relu'))\n",
    "#model.add(Dense(8, activation='relu'))\n",
    "#model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input arrays should have the same number of samples as target arrays. Found 180 input samples and 1079 target samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c278854a6195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/thorben/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/thorben/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;31m# Check that all arrays have the same length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck_array_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m                 \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_array_length_consistency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m                 \u001b[0;31m# Additional checks to avoid users mistakenly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/thorben/.local/lib/python2.7/site-packages/keras/engine/training_utils.pyc\u001b[0m in \u001b[0;36mcheck_array_length_consistency\u001b[0;34m(inputs, targets, weights)\u001b[0m\n\u001b[1;32m    242\u001b[0m                          \u001b[0;34m'the same number of samples as target arrays. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                          \u001b[0;34m'Found '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' input samples '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                          'and ' + str(list(set_y)[0]) + ' target samples.')\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         raise ValueError('All sample_weight arrays should have '\n",
      "\u001b[0;31mValueError\u001b[0m: Input arrays should have the same number of samples as target arrays. Found 180 input samples and 1079 target samples."
     ]
    }
   ],
   "source": [
    "#model.fit(test, train, epochs=10, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for float(): 2017-04-05",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-0395af48fe2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/thorben/.local/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 458\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/thorben/.local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/home/thorben/.local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for float(): 2017-04-05"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions and find the rmse\n",
    "preds = model.predict(x_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
